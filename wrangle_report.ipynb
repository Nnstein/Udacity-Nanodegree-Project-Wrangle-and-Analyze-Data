{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                    Wrangle_Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * `Gathering`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this project were downloaded programatically and gotten from twitter API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * `Accessing`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframes wqere accessed using: .info(), .sample(),.shape, .head(), .duplicated().sum(), .value_counts(), etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    Quality Issues\n",
    "1. MAny columns were not needed for the analysis\n",
    "2. tweet_df: source should only contain the origin of the tweet and it should be a category datatype. \n",
    "3. tweet_df: Inconsistent naming of the created_at, id and full_text columnsÂ¶\n",
    "4. tweet_df: The display_text_range column contains extra characters that are not necessary and it is not int datatype\n",
    "5. tweet_df: some columns have incorrect datatypes\n",
    "6. tweet_df: the timestamp column here contains utc characters and is not datetime\n",
    "7.  archive_df: contains columns that will not be needed\n",
    "8. archive_df: the timestamp column here contains utc characters and is not datetime\n",
    "9. archive_df:source should only contain the origin of the tweet and it should be a category datatype\n",
    "10. archive_df: invalid dog names present\n",
    "\n",
    "####    Tidiness Issues\n",
    "11. Merge the `tweet_clean ` table to the `archive_clean` table, on the *tweet_id*, *timestamp*,*source*, and *text* columns\n",
    "12. archive_df: This df contains values: doggo, floffer, puppo and pupper as column headers\n",
    "13. there is need to Merge the tweet_clean table to the archive_clean table, on the tweet_id, timestamp,source, and text columns\n",
    "14. archive_tweet_concated: All tables should be merged into one table called the twitter_archve_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *`Cleaning`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning was done using the DEFINE, CODE, TEST way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copies of the original dataframes called tweet_clean, image_clean, archive_clean, were made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Issues:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Drop columns not needed using pandas drop method.\n",
    "\n",
    "2. a. Create a dictionary containing the source links as the key and the last part of the links as the values\n",
    "   b. define and apply a function that goes through the source columns and replaces its content with their correspoinding values in the dictionary\n",
    "   c. convert column to a category datatype\n",
    "   \n",
    "3. Rename columns with pandas rename method\n",
    "\n",
    "4. convert the display_text_range column to string data type, and strip it of its first 4 and last character, leaving only number characters.\n",
    "\n",
    "5. Assign a category datatype to lang column and an int datatype to text_range column.\n",
    "\n",
    "6. Convert the values in the timestamp column to a datetime and set tz_convert method to none\n",
    "\n",
    "7. Drop columns not needed using pandas drop method\n",
    "\n",
    "8. strip the last 6 characters from values in the timestamp column of the archive_df dataframe and convert the column to a datetime with pandas astype method\n",
    "\n",
    "9. a. use the tweet_source dictionary\n",
    "   b. define and apply a function that goes through the source columns and replaces its content with their correspoinding values in the  dictionary\n",
    "    c. convert this column to a category datatype\n",
    "    \n",
    "12. Use function to replace all inalid names with 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness Issues:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. a. Join the doggo, floofer, pupper and puppo column joined in a column, and replace missing values with np.nan\n",
    "    b. define a function 'join_column' that joins characters seperated by a comma and apply it to the created column\n",
    "    d. set this column as one pf the columns in archive_clean df\n",
    "    e. Drop the doggo, floofer, puppo and the pupper columns from the archive_clean df and fill empty values with np.nan\n",
    "    \n",
    "11. merge the tweet_clean to the archive_clean on the tweet_id, timestamp, source and text column to a new table called archive_tweet_merged\n",
    "\n",
    "13. a. Merge the archive_tweet_merged and the image_clean df into one table called twitter_archive_table. \n",
    "    b. Drop all records with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * `Storing Data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaned files were saved as \"twitter_archive_master.csv\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
